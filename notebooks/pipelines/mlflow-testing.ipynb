{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-15T22:50:08.274187700Z",
     "start_time": "2023-11-15T22:50:07.642470400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Experiment: artifact_location='mlflow-artifacts:/123960551536115947', creation_time=1700088037390, experiment_id='123960551536115947', last_update_time=1700088037390, lifecycle_stage='active', name='Apple_Models', tags={'mlflow.note.content': 'This is the grocery forecasting project. This '\n",
      "                        'experiment contains the produce models for apples.',\n",
      " 'project_name': 'grocery-forecasting',\n",
      " 'project_quarter': 'Q3-2023',\n",
      " 'store_dept': 'produce',\n",
      " 'team': 'stores-ml'}>, <Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1700088001087, experiment_id='0', last_update_time=1700088001087, lifecycle_stage='active', name='Default', tags={}>]\n",
      "{'lifecycle_stage': 'active', 'name': 'Default'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/.virtualenvs/nfl-data-models/lib/python3.10/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/dev/.virtualenvs/nfl-data-models/lib/python3.10/site-packages/pydantic/_internal/_config.py:318: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from mlflow import MlflowClient\n",
    "from pprint import pprint\n",
    "\n",
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Search experiments without providing query terms behaves effectively as a 'list' action\n",
    "all_experiments = client.search_experiments()\n",
    "\n",
    "print(all_experiments)\n",
    "\n",
    "# Extract the experiment name and lifecycle_stage\n",
    "default_experiment = [\n",
    "    {\"name\": experiment.name, \"lifecycle_stage\": experiment.lifecycle_stage}\n",
    "    for experiment in all_experiments\n",
    "    if experiment.name == \"Default\"\n",
    "][0]\n",
    "\n",
    "pprint(default_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Experiment: artifact_location='mlflow-artifacts:/738046608083083887', creation_time=1700088617418, experiment_id='738046608083083887', last_update_time=1700088617418, lifecycle_stage='active', name='WP_Models', tags={'mlflow.note.content': 'NFL Win Probability ModelsThis experiment contains '\n",
      "                        'models for neutral win probability as well as Vegas '\n",
      "                        'line adjusted win probability.',\n",
      " 'project_name': 'wp-models',\n",
      " 'team': 'nfl-ml'}>\n"
     ]
    }
   ],
   "source": [
    "experiment_description = (\n",
    "    \"NFL Win Probability Models\"\n",
    "    \"This experiment contains models for neutral win probability as well as Vegas line adjusted win probability.\"\n",
    ")\n",
    "\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"wp-models\",\n",
    "    \"team\": \"nfl-ml\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "nfl_wp_experiment = client.create_experiment(name=\"WP_Models\", tags=experiment_tags)\n",
    "\n",
    "wp_experiment = client.search_experiments(\n",
    "    filter_string=\"tags.`project_name` = 'wp-models'\"\n",
    ")\n",
    "\n",
    "pprint(wp_experiment[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T22:50:17.599065300Z",
     "start_time": "2023-11-15T22:50:17.369074800Z"
    }
   },
   "id": "93b6d7b8c7dd13cc"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfl-ml\n"
     ]
    }
   ],
   "source": [
    "# Access individual tag data\n",
    "print(wp_experiment[0].tags[\"team\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T22:50:30.200440300Z",
     "start_time": "2023-11-15T22:50:30.196440700Z"
    }
   },
   "id": "51ce08a20678e51c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from src import WPModel\n",
    "\n",
    "wp_model = WPModel()\n",
    "cal_data = wp_model.import_calibration_data()\n",
    "test_df = cal_data.loc[cal_data['season'] >= 2023]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T23:01:19.712627400Z",
     "start_time": "2023-11-15T23:01:18.426569800Z"
    }
   },
   "id": "b0493d68952d4bf4"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Use the fluent API to set the tracking uri and the active experiment\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Sets the current active experiment to the \"Apple_Models\" experiment and returns the Experiment metadata\n",
    "apple_experiment = mlflow.set_experiment(\"WP_Models\")\n",
    "\n",
    "# Define a run name for this iteration of training.\n",
    "# If this is not set, a unique name will be auto-generated for your run.\n",
    "run_name = \"wp_model_xgb_custom_train_test_split\"\n",
    "\n",
    "# Define an artifact path that the model will be saved to.\n",
    "artifact_path = \"wp_model_xgb_custom_train_test_split\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T23:01:25.143474200Z",
     "start_time": "2023-11-15T23:01:25.048459400Z"
    }
   },
   "id": "8a1ff1cb3838017f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Results: XGBoost with custom train_test_split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a4be12398d21e0a"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.67713\tvalidation_0-auc:0.82905\tvalidation_0-error:0.27677\tvalidation_1-logloss:0.67701\tvalidation_1-auc:0.83616\tvalidation_1-error:0.26513\n",
      "[50]\tvalidation_0-logloss:0.47830\tvalidation_0-auc:0.86121\tvalidation_0-error:0.22791\tvalidation_1-logloss:0.48822\tvalidation_1-auc:0.85296\tvalidation_1-error:0.22974\n",
      "[100]\tvalidation_0-logloss:0.45688\tvalidation_0-auc:0.86309\tvalidation_0-error:0.22628\tvalidation_1-logloss:0.47072\tvalidation_1-auc:0.85420\tvalidation_1-error:0.22835\n",
      "[150]\tvalidation_0-logloss:0.45222\tvalidation_0-auc:0.86456\tvalidation_0-error:0.22496\tvalidation_1-logloss:0.46771\tvalidation_1-auc:0.85493\tvalidation_1-error:0.22791\n",
      "[200]\tvalidation_0-logloss:0.45046\tvalidation_0-auc:0.86532\tvalidation_0-error:0.22438\tvalidation_1-logloss:0.46685\tvalidation_1-auc:0.85523\tvalidation_1-error:0.22708\n",
      "[250]\tvalidation_0-logloss:0.44944\tvalidation_0-auc:0.86581\tvalidation_0-error:0.22404\tvalidation_1-logloss:0.46672\tvalidation_1-auc:0.85522\tvalidation_1-error:0.22708\n",
      "[300]\tvalidation_0-logloss:0.44853\tvalidation_0-auc:0.86628\tvalidation_0-error:0.22379\tvalidation_1-logloss:0.46619\tvalidation_1-auc:0.85545\tvalidation_1-error:0.22721\n",
      "[350]\tvalidation_0-logloss:0.44810\tvalidation_0-auc:0.86648\tvalidation_0-error:0.22362\tvalidation_1-logloss:0.46603\tvalidation_1-auc:0.85547\tvalidation_1-error:0.22721\n",
      "[400]\tvalidation_0-logloss:0.44781\tvalidation_0-auc:0.86663\tvalidation_0-error:0.22347\tvalidation_1-logloss:0.46599\tvalidation_1-auc:0.85545\tvalidation_1-error:0.22797\n",
      "[416]\tvalidation_0-logloss:0.44779\tvalidation_0-auc:0.86664\tvalidation_0-error:0.22347\tvalidation_1-logloss:0.46598\tvalidation_1-auc:0.85545\tvalidation_1-error:0.22797\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train, y_train, X_test, y_test, folds = wp_model.train_test_split(cal_data,2023, 5)\n",
    "clf = wp_model.train_xgclassifier(X_train, y_train, X_test, y_test)\n",
    "scores = clf.evals_result()\n",
    "y_val = clf.predict(X_test)\n",
    "y_pred = clf.predict_proba(X_test, validate_features=True)\n",
    "test_df['wp'] = y_pred[:,1]\n",
    "cols = ['game_id', 'game_seconds_remaining', 'score_differential', 'yardline_100', 'win_probability']\n",
    "test_df = test_df.filter(items=cols)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T23:03:37.806036600Z",
     "start_time": "2023-11-15T23:02:44.185154Z"
    }
   },
   "id": "3b6144bb1b1d3038"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/.virtualenvs/nfl-data-models/lib/python3.10/site-packages/mlflow/models/signature.py:351: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  input_schema = _infer_schema(input_example)\n",
      "/home/dev/.virtualenvs/nfl-data-models/lib/python3.10/site-packages/mlflow/models/signature.py:362: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  output_schema = _infer_schema(prediction)\n",
      "/home/dev/.virtualenvs/nfl-data-models/lib/python3.10/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/dev/.virtualenvs/nfl-data-models/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Calculate error metrics\n",
    "accuracy = accuracy_score(y_val, y_pred[:,1] > .5)\n",
    "error = sum(scores['validation_1']['error']) / len(scores['validation_1']['error'])\n",
    "auc = sum(scores['validation_1']['auc']) / len(scores['validation_1']['auc'])\n",
    "logloss = sum(scores['validation_1']['logloss']) / len(scores['validation_1']['logloss'])\n",
    "\n",
    "# Assemble the metrics we're going to write into a collection\n",
    "metrics = {\"accuracy\": accuracy, \"error\": error, \"auc\": auc, \"logloss\": logloss}\n",
    "\n",
    "# Initiate the MLflow run context\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log the parameters used for the model fit\n",
    "    mlflow.log_params(wp_model.wp_spread_model_sklearn_parameters)\n",
    "\n",
    "    # Log the error metrics that were calculated during validation\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Log an instance of the trained model for later use\n",
    "    mlflow.sklearn.log_model(sk_model=clf, input_example=X_test, artifact_path=artifact_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T23:15:56.458415Z",
     "start_time": "2023-11-15T23:15:54.384206300Z"
    }
   },
   "id": "98514843546f7ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Results: xgboost with scikit-learn train_test_split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebf15d4d3c9a5676"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define a run name for this iteration of training.\n",
    "# If this is not set, a unique name will be auto-generated for your run.\n",
    "run_name = \"wp_model_xgb_sklearn_train_test_split\"\n",
    "\n",
    "# Define an artifact path that the model will be saved to.\n",
    "artifact_path = \"wp_model_xgb_sklearn_train_test_split\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T23:22:36.334379500Z",
     "start_time": "2023-11-15T23:22:36.320410200Z"
    }
   },
   "id": "58465d14b07cc5b7"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.67714\tvalidation_0-auc:0.82942\tvalidation_0-error:0.28308\tvalidation_1-logloss:0.67720\tvalidation_1-auc:0.82861\tvalidation_1-error:0.28494\n",
      "[50]\tvalidation_0-logloss:0.47842\tvalidation_0-auc:0.86113\tvalidation_0-error:0.22786\tvalidation_1-logloss:0.47867\tvalidation_1-auc:0.86086\tvalidation_1-error:0.22843\n",
      "[100]\tvalidation_0-logloss:0.45706\tvalidation_0-auc:0.86302\tvalidation_0-error:0.22618\tvalidation_1-logloss:0.45733\tvalidation_1-auc:0.86273\tvalidation_1-error:0.22640\n",
      "[150]\tvalidation_0-logloss:0.45243\tvalidation_0-auc:0.86447\tvalidation_0-error:0.22480\tvalidation_1-logloss:0.45272\tvalidation_1-auc:0.86417\tvalidation_1-error:0.22519\n",
      "[200]\tvalidation_0-logloss:0.45070\tvalidation_0-auc:0.86521\tvalidation_0-error:0.22418\tvalidation_1-logloss:0.45115\tvalidation_1-auc:0.86480\tvalidation_1-error:0.22472\n",
      "[250]\tvalidation_0-logloss:0.44960\tvalidation_0-auc:0.86576\tvalidation_0-error:0.22393\tvalidation_1-logloss:0.45022\tvalidation_1-auc:0.86525\tvalidation_1-error:0.22430\n",
      "[300]\tvalidation_0-logloss:0.44869\tvalidation_0-auc:0.86622\tvalidation_0-error:0.22370\tvalidation_1-logloss:0.44947\tvalidation_1-auc:0.86562\tvalidation_1-error:0.22407\n",
      "[350]\tvalidation_0-logloss:0.44816\tvalidation_0-auc:0.86646\tvalidation_0-error:0.22355\tvalidation_1-logloss:0.44907\tvalidation_1-auc:0.86577\tvalidation_1-error:0.22391\n",
      "[400]\tvalidation_0-logloss:0.44772\tvalidation_0-auc:0.86672\tvalidation_0-error:0.22337\tvalidation_1-logloss:0.44876\tvalidation_1-auc:0.86595\tvalidation_1-error:0.22366\n",
      "[450]\tvalidation_0-logloss:0.44772\tvalidation_0-auc:0.86672\tvalidation_0-error:0.22337\tvalidation_1-logloss:0.44876\tvalidation_1-auc:0.86595\tvalidation_1-error:0.22366\n",
      "[500]\tvalidation_0-logloss:0.44772\tvalidation_0-auc:0.86672\tvalidation_0-error:0.22337\tvalidation_1-logloss:0.44876\tvalidation_1-auc:0.86595\tvalidation_1-error:0.22366\n",
      "[550]\tvalidation_0-logloss:0.44772\tvalidation_0-auc:0.86672\tvalidation_0-error:0.22337\tvalidation_1-logloss:0.44876\tvalidation_1-auc:0.86595\tvalidation_1-error:0.22366\n",
      "[585]\tvalidation_0-logloss:0.44772\tvalidation_0-auc:0.86672\tvalidation_0-error:0.22337\tvalidation_1-logloss:0.44876\tvalidation_1-auc:0.86595\tvalidation_1-error:0.22366\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wp_model = WPModel()\n",
    "cal_data = wp_model.import_calibration_data()\n",
    "X = cal_data.loc[:, ~cal_data.columns.isin(['season', 'game_id', 'label', 'home_team', 'away_team'])]\n",
    "y = cal_data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "clf = wp_model.train_xgclassifier(X_train, y_train, X_test, y_test)\n",
    "scores = clf.evals_result()\n",
    "\n",
    "y_val = clf.predict(X_test)\n",
    "y_pred = clf.predict_proba(X_test, validate_features=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T23:23:44.329388800Z",
     "start_time": "2023-11-15T23:22:40.777981800Z"
    }
   },
   "id": "f8e8f5a79e78e9e8"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/.virtualenvs/nfl-data-models/lib/python3.10/site-packages/mlflow/models/signature.py:351: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  input_schema = _infer_schema(input_example)\n",
      "/home/dev/.virtualenvs/nfl-data-models/lib/python3.10/site-packages/mlflow/models/signature.py:362: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  output_schema = _infer_schema(prediction)\n",
      "/home/dev/.virtualenvs/nfl-data-models/lib/python3.10/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/dev/.virtualenvs/nfl-data-models/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "# Calculate error metrics\n",
    "accuracy = accuracy_score(y_val, y_pred[:,1] > .5)\n",
    "error = sum(scores['validation_1']['error']) / len(scores['validation_1']['error'])\n",
    "auc = sum(scores['validation_1']['auc']) / len(scores['validation_1']['auc'])\n",
    "logloss = sum(scores['validation_1']['logloss']) / len(scores['validation_1']['logloss'])\n",
    "\n",
    "# Assemble the metrics we're going to write into a collection\n",
    "metrics = {\"accuracy\": accuracy, \"error\": error, \"auc\": auc, \"logloss\": logloss}\n",
    "\n",
    "# Initiate the MLflow run context\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log the parameters used for the model fit\n",
    "    mlflow.log_params(wp_model.wp_spread_model_sklearn_parameters)\n",
    "\n",
    "    # Log the error metrics that were calculated during validation\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Log an instance of the trained model for later use\n",
    "    mlflow.sklearn.log_model(sk_model=clf, input_example=X_test, artifact_path=artifact_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T23:25:43.404499400Z",
     "start_time": "2023-11-15T23:25:39.014447700Z"
    }
   },
   "id": "7d1f1090bd653139"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Results: Stratified split by game id"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a7da014e48bb8b5"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Define a run name for this iteration of training.\n",
    "# If this is not set, a unique name will be auto-generated for your run.\n",
    "run_name = \"wp_model_xgb_stratified_split_game_id\"\n",
    "\n",
    "# Define an artifact path that the model will be saved to.\n",
    "artifact_path = \"wp_model_xgb_stratified_split_game_id\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T23:29:22.244176900Z",
     "start_time": "2023-11-15T23:29:22.194184900Z"
    }
   },
   "id": "45321d378f01a03d"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.67714\tvalidation_0-auc:0.82926\tvalidation_0-error:0.26146\tvalidation_1-logloss:0.67714\tvalidation_1-auc:0.82858\tvalidation_1-error:0.26222\n",
      "[50]\tvalidation_0-logloss:0.47806\tvalidation_0-auc:0.86147\tvalidation_0-error:0.22745\tvalidation_1-logloss:0.47922\tvalidation_1-auc:0.86012\tvalidation_1-error:0.22922\n",
      "[100]\tvalidation_0-logloss:0.45667\tvalidation_0-auc:0.86333\tvalidation_0-error:0.22576\tvalidation_1-logloss:0.45840\tvalidation_1-auc:0.86183\tvalidation_1-error:0.22756\n",
      "[150]\tvalidation_0-logloss:0.45200\tvalidation_0-auc:0.86477\tvalidation_0-error:0.22459\tvalidation_1-logloss:0.45406\tvalidation_1-auc:0.86316\tvalidation_1-error:0.22665\n",
      "[200]\tvalidation_0-logloss:0.45026\tvalidation_0-auc:0.86550\tvalidation_0-error:0.22400\tvalidation_1-logloss:0.45253\tvalidation_1-auc:0.86382\tvalidation_1-error:0.22589\n",
      "[250]\tvalidation_0-logloss:0.44919\tvalidation_0-auc:0.86603\tvalidation_0-error:0.22362\tvalidation_1-logloss:0.45162\tvalidation_1-auc:0.86428\tvalidation_1-error:0.22548\n",
      "[300]\tvalidation_0-logloss:0.44832\tvalidation_0-auc:0.86647\tvalidation_0-error:0.22325\tvalidation_1-logloss:0.45088\tvalidation_1-auc:0.86468\tvalidation_1-error:0.22531\n",
      "[350]\tvalidation_0-logloss:0.44784\tvalidation_0-auc:0.86671\tvalidation_0-error:0.22304\tvalidation_1-logloss:0.45053\tvalidation_1-auc:0.86485\tvalidation_1-error:0.22523\n",
      "[400]\tvalidation_0-logloss:0.44762\tvalidation_0-auc:0.86683\tvalidation_0-error:0.22300\tvalidation_1-logloss:0.45036\tvalidation_1-auc:0.86495\tvalidation_1-error:0.22524\n",
      "[450]\tvalidation_0-logloss:0.44762\tvalidation_0-auc:0.86683\tvalidation_0-error:0.22299\tvalidation_1-logloss:0.45036\tvalidation_1-auc:0.86495\tvalidation_1-error:0.22524\n",
      "[500]\tvalidation_0-logloss:0.44762\tvalidation_0-auc:0.86683\tvalidation_0-error:0.22299\tvalidation_1-logloss:0.45036\tvalidation_1-auc:0.86495\tvalidation_1-error:0.22524\n",
      "[550]\tvalidation_0-logloss:0.44762\tvalidation_0-auc:0.86683\tvalidation_0-error:0.22299\tvalidation_1-logloss:0.45036\tvalidation_1-auc:0.86495\tvalidation_1-error:0.22524\n"
     ]
    }
   ],
   "source": [
    "wp_model = WPModel()\n",
    "cal_data = wp_model.import_calibration_data()\n",
    "X = cal_data.loc[:, ~cal_data.columns.isin(['season', 'game_id', 'label', 'home_team', 'away_team'])]\n",
    "y = cal_data['label']\n",
    "groups = cal_data['game_id']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=groups)\n",
    "\n",
    "clf = wp_model.train_xgclassifier(X_train, y_train, X_test, y_test)\n",
    "scores = clf.evals_result()\n",
    "y_val = clf.predict(X_test)\n",
    "y_pred = clf.predict_proba(X_test, validate_features=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T23:30:26.396078800Z",
     "start_time": "2023-11-15T23:29:25.357818600Z"
    }
   },
   "id": "bc2c14386dcdc849"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/.virtualenvs/nfl-data-models/lib/python3.10/site-packages/mlflow/models/signature.py:351: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  input_schema = _infer_schema(input_example)\n",
      "/home/dev/.virtualenvs/nfl-data-models/lib/python3.10/site-packages/mlflow/models/signature.py:362: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  output_schema = _infer_schema(prediction)\n",
      "/home/dev/.virtualenvs/nfl-data-models/lib/python3.10/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/dev/.virtualenvs/nfl-data-models/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "# Calculate error metrics\n",
    "accuracy = accuracy_score(y_val, y_pred[:,1] > .5)\n",
    "error = sum(scores['validation_1']['error']) / len(scores['validation_1']['error'])\n",
    "auc = sum(scores['validation_1']['auc']) / len(scores['validation_1']['auc'])\n",
    "logloss = sum(scores['validation_1']['logloss']) / len(scores['validation_1']['logloss'])\n",
    "\n",
    "# Assemble the metrics we're going to write into a collection\n",
    "metrics = {\"accuracy\": accuracy, \"error\": error, \"auc\": auc, \"logloss\": logloss}\n",
    "\n",
    "# Initiate the MLflow run context\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log the parameters used for the model fit\n",
    "    mlflow.log_params(wp_model.wp_spread_model_sklearn_parameters)\n",
    "\n",
    "    # Log the error metrics that were calculated during validation\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Log an instance of the trained model for later use\n",
    "    mlflow.sklearn.log_model(sk_model=clf, input_example=X_test, artifact_path=artifact_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T23:30:51.795575200Z",
     "start_time": "2023-11-15T23:30:47.408937900Z"
    }
   },
   "id": "6fd7a4ccea6b4e46"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Results: GroupKFold"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e2868e402d840f5"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Define a run name for this iteration of training.\n",
    "# If this is not set, a unique name will be auto-generated for your run.\n",
    "run_name = \"wp_model_xgb_groupkfold\"\n",
    "\n",
    "# Define an artifact path that the model will be saved to.\n",
    "artifact_path = \"wp_model_xgb_groupkfold\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T23:32:21.532948900Z",
     "start_time": "2023-11-15T23:32:21.526931100Z"
    }
   },
   "id": "a9b09cbd80150695"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.67739\tvalidation_0-auc:0.82634\tvalidation_0-error:0.26525\tvalidation_1-logloss:0.67654\tvalidation_1-auc:0.84121\tvalidation_1-error:0.25253\n",
      "[50]\tvalidation_0-logloss:0.48214\tvalidation_0-auc:0.85813\tvalidation_0-error:0.23143\tvalidation_1-logloss:0.46683\tvalidation_1-auc:0.87317\tvalidation_1-error:0.21397\n",
      "[100]\tvalidation_0-logloss:0.46103\tvalidation_0-auc:0.86008\tvalidation_0-error:0.22949\tvalidation_1-logloss:0.44295\tvalidation_1-auc:0.87443\tvalidation_1-error:0.21341\n",
      "[150]\tvalidation_0-logloss:0.45647\tvalidation_0-auc:0.86153\tvalidation_0-error:0.22814\tvalidation_1-logloss:0.43828\tvalidation_1-auc:0.87532\tvalidation_1-error:0.21197\n",
      "[200]\tvalidation_0-logloss:0.45465\tvalidation_0-auc:0.86233\tvalidation_0-error:0.22760\tvalidation_1-logloss:0.43687\tvalidation_1-auc:0.87570\tvalidation_1-error:0.21157\n",
      "[250]\tvalidation_0-logloss:0.45370\tvalidation_0-auc:0.86278\tvalidation_0-error:0.22730\tvalidation_1-logloss:0.43631\tvalidation_1-auc:0.87586\tvalidation_1-error:0.21156\n",
      "[300]\tvalidation_0-logloss:0.45273\tvalidation_0-auc:0.86330\tvalidation_0-error:0.22700\tvalidation_1-logloss:0.43576\tvalidation_1-auc:0.87605\tvalidation_1-error:0.21126\n",
      "[350]\tvalidation_0-logloss:0.45217\tvalidation_0-auc:0.86358\tvalidation_0-error:0.22686\tvalidation_1-logloss:0.43546\tvalidation_1-auc:0.87612\tvalidation_1-error:0.21138\n",
      "[400]\tvalidation_0-logloss:0.45180\tvalidation_0-auc:0.86377\tvalidation_0-error:0.22674\tvalidation_1-logloss:0.43528\tvalidation_1-auc:0.87618\tvalidation_1-error:0.21127\n",
      "[450]\tvalidation_0-logloss:0.45180\tvalidation_0-auc:0.86377\tvalidation_0-error:0.22674\tvalidation_1-logloss:0.43528\tvalidation_1-auc:0.87618\tvalidation_1-error:0.21127\n",
      "[498]\tvalidation_0-logloss:0.45180\tvalidation_0-auc:0.86377\tvalidation_0-error:0.22674\tvalidation_1-logloss:0.43529\tvalidation_1-auc:0.87618\tvalidation_1-error:0.21127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "wp_model = WPModel()\n",
    "cal_data = wp_model.import_calibration_data()\n",
    "X = cal_data.loc[:, ~cal_data.columns.isin(['season', 'game_id', 'label', 'home_team', 'away_team'])]\n",
    "y = cal_data['label']\n",
    "groups = cal_data['game_id']\n",
    "\n",
    "group_fold = GroupKFold(n_splits=5)\n",
    "for train_index, test_index in group_fold.split(X, y, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "clf = wp_model.train_xgclassifier(X_train, y_train, X_test, y_test)\n",
    "scores = clf.evals_result()\n",
    "y_val = clf.predict(X_test)\n",
    "y_pred = clf.predict_proba(X_test, validate_features=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T23:33:58.144172300Z",
     "start_time": "2023-11-15T23:33:02.868226500Z"
    }
   },
   "id": "26b77fb3f4442146"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/.virtualenvs/nfl-data-models/lib/python3.10/site-packages/mlflow/models/signature.py:351: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  input_schema = _infer_schema(input_example)\n",
      "/home/dev/.virtualenvs/nfl-data-models/lib/python3.10/site-packages/mlflow/models/signature.py:362: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  output_schema = _infer_schema(prediction)\n",
      "/home/dev/.virtualenvs/nfl-data-models/lib/python3.10/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/dev/.virtualenvs/nfl-data-models/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "# Calculate error metrics\n",
    "accuracy = accuracy_score(y_val, y_pred[:,1] > 0.5)\n",
    "error = sum(scores['validation_1']['error']) / len(scores['validation_1']['error'])\n",
    "auc = sum(scores['validation_1']['auc']) / len(scores['validation_1']['auc'])\n",
    "logloss = sum(scores['validation_1']['logloss']) / len(scores['validation_1']['logloss'])\n",
    "\n",
    "# Assemble the metrics we're going to write into a collection\n",
    "metrics = {\"accuracy\": accuracy, \"error\": error, \"auc\": auc, \"logloss\": logloss}\n",
    "\n",
    "# Initiate the MLflow run context\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log the parameters used for the model fit\n",
    "    mlflow.log_params(wp_model.wp_spread_model_sklearn_parameters)\n",
    "\n",
    "    # Log the error metrics that were calculated during validation\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Log an instance of the trained model for later use\n",
    "    mlflow.sklearn.log_model(sk_model=clf, input_example=X_test, artifact_path=artifact_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T23:35:05.465496800Z",
     "start_time": "2023-11-15T23:35:01.593604700Z"
    }
   },
   "id": "cb128e64ded77b60"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
